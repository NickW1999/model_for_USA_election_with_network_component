{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c1ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ada534",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in state names, abbreviations and FIPS codes\n",
    "stateabbr=pd.read_csv('msc_data_raw/stateabbrevations.csv')\n",
    "StateFIPS=pd.read_excel('msc_data_raw/state-geocodes-v2016.xls')\n",
    "stateabbr=stateabbr.set_index('State')\n",
    "StateFIPS.columns=StateFIPS.iloc[3]\n",
    "StateFIPS=StateFIPS.iloc[4:,2:]\n",
    "StateFIPS.columns= ['State FIPS', 'State']\n",
    "StateFIPS=StateFIPS.set_index('State')\n",
    "Stateinfo=pd.concat([stateabbr, StateFIPS],axis=1, sort=False)\n",
    "#Stateinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc314913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-54f5a937a0bc>:40: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  if len(votesdem.loc[i])>1:\n",
      "<ipython-input-3-54f5a937a0bc>:41: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  votesdem.loc[i]['candidatevotes'] = sum(votesdem.loc[i]['candidatevotes'])\n",
      "<ipython-input-3-54f5a937a0bc>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  votesdem.loc[i]['candidatevotes'] = sum(votesdem.loc[i]['candidatevotes'])\n",
      "<ipython-input-3-54f5a937a0bc>:46: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  if len(votesrep.loc[i])>1:\n",
      "<ipython-input-3-54f5a937a0bc>:47: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  votesrep.loc[i]['candidatevotes'] = sum(votesrep.loc[i]['candidatevotes'])\n",
      "<ipython-input-3-54f5a937a0bc>:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  votesrep.loc[i]['candidatevotes'] = sum(votesrep.loc[i]['candidatevotes'])\n",
      "<ipython-input-3-54f5a937a0bc>:62: RuntimeWarning: invalid value encountered in true_divide\n",
      "  votesdem['share of dem and rep']=np.array(votesdem['percentage of total'])/(np.array(votesdem['percentage of total'])+np.array(votesrep['percentage of total']))\n",
      "<ipython-input-3-54f5a937a0bc>:63: RuntimeWarning: invalid value encountered in true_divide\n",
      "  votesrep['share of dem and rep']=np.array(votesrep['percentage of total'])/(np.array(votesdem['percentage of total'])+np.array(votesrep['percentage of total']))\n"
     ]
    }
   ],
   "source": [
    "## Getting the election results and selection the useful ones\n",
    "votes=pd.read_csv('msc_data_raw/election results 2000-2020.csv' )\n",
    "\n",
    "#isolating the dems\n",
    "votesdem=votes[votes['party']== 'DEMOCRAT']#.dropna()\n",
    "votesdem=votesdem.loc[votesdem['totalvotes']>0.5]\n",
    "votesdem=votesdem.loc[votesdem['county_fips']>2]\n",
    "votesdem=votesdem.fillna(0)\n",
    "#isolating the reps\n",
    "votesrep=votes[votes['party']== 'REPUBLICAN']#.dropna()\n",
    "votesrep=votesrep.loc[votesrep['totalvotes']>0.5]\n",
    "votesrep=votesrep.loc[votesrep['county_fips']>2]\n",
    "votesrep=votesrep.fillna(0)\n",
    "\n",
    "#fixing the FIPS and setting them as well as the years as index\n",
    "\n",
    "fips=votesdem['county_fips'].copy()\n",
    "fipslist=[]\n",
    "\n",
    "for i in fips:\n",
    "    if len(str(round(i)))==4:\n",
    "        fipslist.append('0'+str(round(i)))\n",
    "    else:\n",
    "        fipslist.append(str(round(i)))\n",
    "votesdem['FIPS']=fipslist\n",
    "votesdem=votesdem.set_index(['year','FIPS'])\n",
    "\n",
    "fips=votesrep['county_fips'].copy()\n",
    "fipslist=[]\n",
    "for i in fips:\n",
    "    if len(str(round(i)))==4:\n",
    "        fipslist.append('0'+str(round(i)))\n",
    "    else:\n",
    "        fipslist.append(str(round(i)))\n",
    "votesrep['FIPS']=fipslist\n",
    "votesrep=votesrep.set_index(['year','FIPS'])\n",
    "#delete duplicates due to several voting methodes especially in 2020\n",
    "\n",
    "for i in votesdem.index.unique():\n",
    "    if len(votesdem.loc[i])>1:\n",
    "        votesdem.loc[i]['candidatevotes'] = sum(votesdem.loc[i]['candidatevotes'])\n",
    "selection=np.array(votesdem['mode']=='TOTAL')\n",
    "votesdem=votesdem.loc[selection]\n",
    "\n",
    "for i in votesrep.index.unique():\n",
    "    if len(votesrep.loc[i])>1:\n",
    "        votesrep.loc[i]['candidatevotes'] = sum(votesrep.loc[i]['candidatevotes'])\n",
    "selection= np.array(votesrep['mode']=='TOTAL')\n",
    "votesrep=votesrep.loc[selection]\n",
    "\n",
    "# use only the usefull columns\n",
    "\n",
    "votesdem=votesdem.loc[:,['candidatevotes','totalvotes']]\n",
    "votesrep=votesrep.loc[:,['candidatevotes','totalvotes']]\n",
    "votesdem.columns.names = ['variables']\n",
    "votesrep.columns.names =[ 'variables']\n",
    "#calculating the percentages\n",
    "\n",
    "votesdem['percentage of total']=votesdem['candidatevotes']/votesdem['totalvotes']\n",
    "votesrep['percentage of total']=votesrep['candidatevotes']/votesrep['totalvotes']\n",
    "\n",
    "votesdem['share of dem and rep']=np.array(votesdem['percentage of total'])/(np.array(votesdem['percentage of total'])+np.array(votesrep['percentage of total']))\n",
    "votesrep['share of dem and rep']=np.array(votesrep['percentage of total'])/(np.array(votesdem['percentage of total'])+np.array(votesrep['percentage of total']))\n",
    "\n",
    "votesdem['third party']=1-np.array(votesdem['percentage of total'])-np.array(votesrep['percentage of total'])\n",
    "votesrep['third party']=1-np.array(votesdem['percentage of total'])-np.array(votesrep['percentage of total'])\n",
    "\n",
    "votesdem=votesdem.unstack(level='year')\n",
    "votesrep=votesrep.unstack(level='year')\n",
    "\n",
    "#fix some missing values from 2020\n",
    "results2020=pd.read_csv('msc_data_raw/2020_US_County_Level_Presidential_Results.csv')\n",
    "fipslist=[]\n",
    "\n",
    "for i in results2020['county_fips']:\n",
    "    if len(str(round(i)))==4:\n",
    "        fipslist.append('0'+str(round(i)))\n",
    "    else:\n",
    "        fipslist.append(str(round(i)))\n",
    "results2020['county_fips']=fipslist\n",
    "results2020=results2020.set_index('county_fips')\n",
    "results2020\n",
    "for i in votesdem[votesdem.isna().any(axis=1)].index[1:]:\n",
    "    if i not in ['36000','51515']:\n",
    "        votesdem.loc[i].iloc[5]=results2020.loc[i,'votes_dem']\n",
    "        votesrep.loc[i].iloc[5]=results2020.loc[i,'votes_gop']\n",
    "        votesdem.loc[i].iloc[11]=results2020.loc[i,'total_votes']\n",
    "        votesrep.loc[i].iloc[11]=results2020.loc[i,'total_votes']\n",
    "        votesdem.loc[i].iloc[17]=results2020.loc[i,'per_dem']\n",
    "        votesrep.loc[i].iloc[17]=results2020.loc[i,'per_gop']\n",
    "        votesdem.loc[i].iloc[23]=results2020.loc[i,'per_dem']\n",
    "        votesrep.loc[i].iloc[23]=results2020.loc[i,'per_gop']\n",
    "        votesdem.loc[i].iloc[-1]=0\n",
    "        votesrep.loc[i].iloc[-1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563fc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cleaning SCI data for missing counties\n",
    "SCI=pd.read_csv('msc_data_raw/county_county_aug2020.tsv', sep='\\t').dropna()\n",
    "fipslist=[]\n",
    "notused1=[]\n",
    "fips=votesdem.index\n",
    "for i in SCI.loc[:,'user_loc']:\n",
    "    if len(str(round(i)))==4:\n",
    "        fipslist.append('0'+str(round(i)))\n",
    "    else:\n",
    "        fipslist.append(str(round(i)))\n",
    "    if fipslist[-1] in fips:\n",
    "        notused1.append(False)\n",
    "    else:\n",
    "        notused1.append(True)\n",
    "SCI.loc[:,'user_loc']=fipslist\n",
    "fipslist=[]\n",
    "notused2=[]\n",
    "for i in SCI.loc[:,'fr_loc']:\n",
    "    temp=str(round(i))\n",
    "    if len(temp)==4:\n",
    "        fipslist.append('0'+temp)\n",
    "    else:\n",
    "        fipslist.append(temp)\n",
    "    if fipslist[-1] in fips:\n",
    "        notused2.append(False)\n",
    "    else:\n",
    "        notused2.append(True)\n",
    "SCI.loc[:,'fr_loc']=fipslist\n",
    "notused=np.array(notused1)+np.array(notused2)\n",
    "SCI=SCI.drop(SCI.index[notused])\n",
    "SCI=SCI.set_index(['user_loc','fr_loc'])\n",
    "SCI=SCI.unstack('fr_loc')\n",
    "SCI=SCI['scaled_sci']\n",
    "SCI.to_csv('msc_thesis/data/SCI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc163bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculation the exposure\n",
    "SCIvotescorrecteddem=pd.DataFrame(index=SCI.index)\n",
    "SCIvotesdem=pd.DataFrame(index=SCI.index)\n",
    "SCIvotersdem=pd.DataFrame(index=SCI.index)\n",
    "\n",
    "#generation an empty dataframe\n",
    "for j in [2000,2004,2008,2012,2016,2020]:\n",
    "    SCIvotesdem[j]=np.repeat(np.nan,len(SCI.index))\n",
    "    SCIvotescorrecteddem[j]=np.repeat(np.nan,len(SCI.index))\n",
    "SCIvotesrep=SCIvotesdem.copy()\n",
    "SCIvotersrep= SCIvotescorrecteddem.copy()   \n",
    "for i in SCI.index:\n",
    "    for j in [2000,2004,2008,2012,2016,2020]:\n",
    "        SCIvotesdem.loc[i,j]=sum((SCI.loc[i]*votesdem.loc[:,'candidatevotes'].loc[:,j]).dropna())\n",
    "        SCIvotersdem.loc[i,j]=sum((SCI.loc[i]*votesdem.loc[:,'totalvotes'].loc[:,j]).dropna())\n",
    "        SCIvotesrep.loc[i,j]=sum((SCI.loc[i]*votesrep.loc[:,'candidatevotes'].loc[:,j]).dropna())\n",
    "        SCIvotersrep.loc[i,j]=sum((SCI.loc[i]*votesrep.loc[:,'totalvotes'].loc[:,j]).dropna())\n",
    "exposuredem=SCIvotesdem/SCIvotersdem \n",
    "SCIvotersdem.to_csv('msc_thesis/data/eligible friends')\n",
    "exposurerep=SCIvotesrep/SCIvotersrep     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding the voteshares and exposure to the cleaned dataset\n",
    "total_time_data=pd.concat([votesdem['share of dem and rep'],votesrep['share of dem and rep'],votesrep['third party'],exposurerep,exposuredem],axis=1)\n",
    "total_time_data.columns=[np.repeat(['dem_votesshare','rep_voteshare','third party vote','exposure_rep','exposure_dem'],6),\n",
    "                        [2000,2004,2008,2012,2016,2020,2000,2004,2008,2012,2016,2020,2000,2004,2008,2012,2016,2020,\n",
    "                        2000,2004,2008,2012,2016,2020,2000,2004,2008,2012,2016,2020]]\n",
    "total_time_data=total_time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unemployment data\n",
    "df_unemployment=pd.read_excel('msc_data_raw/Unemployment2000-2020.xlsx' )\n",
    "df_unemployment.columns=df_unemployment.iloc[3]\n",
    "df_unemployment=df_unemployment.dropna()\n",
    "df_unemployment=df_unemployment.iloc[1:,:]\n",
    "df_unemployment=df_unemployment.set_index('FIPS_Code')\n",
    "df_unemployment.index.names=['FIPS']\n",
    "\n",
    "unemployment_rate_list=[]\n",
    "for i in df_unemployment.columns:\n",
    "    if 'rate' in i:\n",
    "        if i[-4:] in ['2000','2004','2008','2012','2016','2019']:\n",
    "            unemployment_rate_list.append(i)\n",
    "df_unemployment=df_unemployment.loc[:,unemployment_rate_list]\n",
    "df_unemployment.columns=[['unemployment rate','unemployment rate','unemployment rate','unemployment rate','unemployment rate','unemployment rate'],\n",
    "                        [2000,2004,2008,2012,2016,2020]]\n",
    "df_unemployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0006b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the age and racial data, this is split in the two seperate decades\n",
    "## first the age groups \n",
    "df_raceandage10till20=pd.read_csv('msc_data_raw/racial and age composition 2010-2019.csv', encoding = 'utf-16')\n",
    "#correcting the FIPS codes\n",
    "fipslist=[]\n",
    "fipslistcounty=[]\n",
    "for i in range(len(df_raceandage10till20)):\n",
    "    if len(str(df_raceandage10till20['COUNTY'].iloc[i]))==1:\n",
    "        fipslistcounty.append('00' +str(df_raceandage10till20['COUNTY'].iloc[i]))\n",
    "    elif len(str(df_raceandage10till20['COUNTY'].iloc[i]))==2:\n",
    "        fipslistcounty.append('0' +str(df_raceandage10till20['COUNTY'].iloc[i]))\n",
    "    elif len(str(df_raceandage10till20['COUNTY'].iloc[i]))==3:\n",
    "        fipslistcounty.append(str(df_raceandage10till20['COUNTY'].iloc[i]))\n",
    "for i in range(len(df_raceandage10till20)):\n",
    "    if len(str(df_raceandage10till20['STATE'].iloc[i]))==1:\n",
    "        fipslist.append('0' +str(df_raceandage10till20['STATE'].iloc[i])+fipslistcounty[i])\n",
    "    elif len(str(df_raceandage10till20['STATE'].iloc[i]))==2:\n",
    "        fipslist.append(str(df_raceandage10till20['STATE'].iloc[i])+fipslistcounty[i])\n",
    "df_raceandage10till20['FIPS']=fipslist\n",
    "df_raceandage10till20['County_FIPS']=fipslistcounty\n",
    "df_ages1020=df_raceandage10till20\n",
    "\n",
    "#selecting the election years \n",
    "election_years=np.array(df_ages1020['YEAR']==5)+np.array(df_ages1020['YEAR']==9)+np.array(df_ages1020['YEAR']==12)\n",
    "\n",
    "df_ages1020=df_ages1020.loc[election_years]\n",
    "years=[]\n",
    "for i in range(len(df_ages1020['YEAR'])//57):\n",
    "    years.extend(np.repeat(2012,19))\n",
    "    years.extend(np.repeat(2016,19))\n",
    "    years.extend(np.repeat(2020,19))\n",
    "df_ages1020['YEARS']=years\n",
    "df_ages1020=df_ages1020.loc[:,['FIPS','YEARS','AGEGRP','TOT_POP']]\n",
    "\n",
    "eligible=[]\n",
    "yeartemp=[]\n",
    "FIPStemp=[]\n",
    "for i in df_ages1020['FIPS'].unique():\n",
    "    temp=df_ages1020.loc[df_ages1020['FIPS']==i]\n",
    "    for j in [2012,2016,2020]:\n",
    "        temp2=temp.loc[df_ages1020['YEARS']==j]\n",
    "               \n",
    "        FIPStemp.append(i)\n",
    "        eligible.append(temp2.iloc[0,3]-temp2.iloc[1,3])\n",
    "    yeartemp.extend([2012,2016,2020])   \n",
    "eligiblevoter10till20=pd.DataFrame(eligible,index=[yeartemp,FIPStemp])\n",
    "eligiblevoter10till20.index.names=['YEARS','FIPS']\n",
    "eligiblevoter10till20=eligiblevoter10till20.unstack('YEARS')\n",
    "eligiblevoter10till20.columns=pd.MultiIndex.from_tuples([(  'eligible voters', 2012),\n",
    "            (  'eligible voters', 2016),\n",
    "            (  'eligible voters', 2020),\n",
    "            ],\n",
    "           names=[ 'agegroups', 'YEARS'])\n",
    "#sorting the data in the correct bin\n",
    "yeartemp=[]\n",
    "FIPStemp=[]\n",
    "agegrouptemp=[]\n",
    "percentagetemp=[]\n",
    "for i in df_ages1020['FIPS'].unique():\n",
    "    temp=df_ages1020.loc[df_ages1020['FIPS']==i]\n",
    "    for j in [2012,2016,2020]:\n",
    "        temp2=temp.loc[df_ages1020['YEARS']==j]\n",
    "        temp2=temp2.loc[:,'TOT_POP']/temp2.iloc[0,3]\n",
    "        yeartemp.extend(np.repeat(j,4))\n",
    "        FIPStemp.extend(np.repeat(i,4))\n",
    "        agegrouptemp.extend(['0-19 years old','20-29 years old','30-44 years old','45-64 years old'])\n",
    "        percentagetemp.append(sum(temp2.iloc[1:5]))\n",
    "        percentagetemp.append(sum(temp2.iloc[5:7]))\n",
    "        percentagetemp.append(sum(temp2.iloc[7:10]))\n",
    "        percentagetemp.append(sum(temp2.iloc[10:14]))\n",
    "        \n",
    "df_agegroups1020=pd.DataFrame(percentagetemp,index=[yeartemp,FIPStemp,agegrouptemp])\n",
    "df_agegroups1020.index.names=['YEARS','FIPS','agegroups']\n",
    "df_agegroups1020=df_agegroups1020.sort_index(axis=0,level=2)\n",
    "\n",
    "df_agegroups1020=df_agegroups1020.unstack(['agegroups','YEARS'])\n",
    "df_agegroups1020.columns=pd.MultiIndex.from_tuples([(  '0-19 years old', 2012),\n",
    "            (  '0-19 years old', 2016),\n",
    "            (  '0-19 years old', 2020),\n",
    "            ( '20-29 years old', 2012),\n",
    "            ( '20-29 years old', 2016),\n",
    "            ( '20-29 years old', 2020),\n",
    "            ( '30-44 years old', 2012),\n",
    "            ( '30-44 years old', 2016),\n",
    "            ( '30-44 years old', 2020),\n",
    "            ( '45-64 years old', 2012),\n",
    "            ( '45-64 years old', 2016),\n",
    "            ('45-64 years old', 2020)],\n",
    "           names=[ 'agegroups', 'YEARS'])\n",
    "#now the same for the 2000-2010\n",
    "df_ages00till10=pd.read_csv('msc_data_raw/age composition 2000-2010.csv').dropna()\n",
    "fipslist=[]\n",
    "fipslistcounty=[]\n",
    "for i in range(len(df_ages00till10)):\n",
    "    if len(str(df_ages00till10['COUNTY'].iloc[i]))==1:\n",
    "        fipslistcounty.append('00' +str(df_ages00till10['COUNTY'].iloc[i]))\n",
    "    elif len(str(df_ages00till10['COUNTY'].iloc[i]))==2:\n",
    "        fipslistcounty.append('0' +str(df_ages00till10['COUNTY'].iloc[i]))\n",
    "    elif len(str(df_ages00till10['COUNTY'].iloc[i]))==3:\n",
    "        fipslistcounty.append(str(df_ages00till10['COUNTY'].iloc[i]))\n",
    "for i in range(len(df_ages00till10)):\n",
    "    if len(str(df_ages00till10['STATE'].iloc[i]))==1:\n",
    "        fipslist.append('0' +str(df_ages00till10['STATE'].iloc[i])+fipslistcounty[i])\n",
    "    elif len(str(df_ages00till10['STATE'].iloc[i]))==2:\n",
    "        fipslist.append(str(df_ages00till10['STATE'].iloc[i])+fipslistcounty[i])\n",
    "df_ages00till10['FIPS']=fipslist\n",
    "df_ages00till10=df_ages00till10.loc[df_ages00till10.loc[:,'SEX']==0]\n",
    "df_ages00till10=df_ages00till10[['AGEGRP','POPESTIMATE2000','POPESTIMATE2004','POPESTIMATE2008','FIPS']]\n",
    "df_ages00till10.columns=['AGEGRP',2000,2004,2008,'FIPS']\n",
    "\n",
    "temp1 =df_ages00till10.loc[df_ages00till10.loc[:,'AGEGRP']==0].set_index('FIPS').drop('AGEGRP',axis=1)\n",
    "temp2 =df_ages00till10.loc[df_ages00till10.loc[:,'AGEGRP']==1].set_index('FIPS').drop('AGEGRP',axis=1)\n",
    "eligiblevoter00till10=pd.DataFrame(index=temp1.index,columns=[np.repeat(['totalpop','underage','eligible voters'],3),\n",
    "                                                              [2000,2004,2008,2000,2004,2008,2000,2004,2008]])\n",
    "eligiblevoter00till10['totalpop']=temp1\n",
    "eligiblevoter00till10['underage']=temp2\n",
    "eligiblevoter00till10['eligible voters']=eligiblevoter00till10['totalpop']-eligiblevoter00till10['underage']\n",
    "\n",
    "df_eligibevoters=pd.concat([eligiblevoter00till10['eligible voters'],eligiblevoter10till20],axis=1).dropna()\n",
    "df_eligibevoters.columns=[np.repeat('eligible voters',6),[2000,2004,2008,2012,2016,2020]]\n",
    "voterturnout=pd.concat([votesdem['totalvotes'],df_eligibevoters],axis=1).dropna()\n",
    "voterturnout.columns=[np.repeat(['total votes','eligible voters'],6),\n",
    "[2000,2004,2008,2012,2016,2020,2000,2004,2008,2012,2016,2020]]\n",
    "for i in [2000,2004,2008,2012,2016,2020]:\n",
    "    voterturnout['voter turnout '+str(i)]=voterturnout['total votes',i]/voterturnout['eligible voters',i]\n",
    "voterturnout.columns=[np.repeat(['total votes','eligible voters','voter turnout'],6),\n",
    "[2000,2004,2008,2012,2016,2020,2000,2004,2008,2012,2016,2020,2000,2004,2008,2012,2016,2020]]\n",
    "\n",
    "#save eligible voters for the simulation\n",
    "voterturnout['eligible voters'].to_csv('msc_thesis/data/eligible voters')\n",
    "\n",
    "df_ages00till10=df_ages00till10.set_index(['FIPS']).dropna()\n",
    "\n",
    "yeartemp=[]\n",
    "FIPStemp=[]\n",
    "agegrouptemp=[]\n",
    "percentagetemp=[]\n",
    "for i in df_ages00till10.index.unique():\n",
    "    temp=df_ages00till10.loc[i]\n",
    "    temp2=temp.loc[:,[2000,2004,2008]]\n",
    "    temp2=temp2/temp2.iloc[0]\n",
    "    FIPStemp.extend(np.repeat(i,4))\n",
    "    agegrouptemp.extend(['0-19 years old','20-29 years old','30-44 years old','45-64 years old'])\n",
    "    percentagetemp.append(np.sum(temp2.iloc[1:5],axis=0))\n",
    "    percentagetemp.append(np.sum(temp2.iloc[5:7],axis=0))\n",
    "    percentagetemp.append(np.sum(temp2.iloc[7:10],axis=0))\n",
    "    percentagetemp.append(np.sum(temp2.iloc[10:14],axis=0))\n",
    "    \n",
    "df_ages00till10=pd.DataFrame(percentagetemp,index=[FIPStemp,agegrouptemp])\n",
    "df_ages00till10.index.names=['FIPS','age groups']\n",
    "df_ages00till10=df_ages00till10.unstack('age groups') \n",
    "df_ages00till10=pd.DataFrame(percentagetemp,index=[FIPStemp,agegrouptemp])\n",
    "df_ages00till10.index.names=['FIPS','age groups']\n",
    "df_ages00till10.columns.names=['YEARS']\n",
    "df_ages00till10=df_ages00till10.unstack('age groups')\n",
    "df_ages00till10=df_ages00till10.stack('YEARS').unstack('YEARS')\n",
    "df_ages=pd.concat([df_ages00till10,df_agegroups1020],axis=1).dropna()\n",
    "df_ages=df_ages.sort_index(axis=1,level='age groups')\n",
    "\n",
    "\n",
    "#racial composition\n",
    "df_allagesrace1020=df_raceandage10till20.loc[df_raceandage10till20['AGEGRP']==0]\n",
    "election_years=np.array(df_allagesrace1020['YEAR']==5)+np.array(df_allagesrace1020['YEAR']==9)+np.array(df_allagesrace1020['YEAR']==12)\n",
    "df_allagesrace1020=df_allagesrace1020.loc[election_years ]\n",
    "years=[]\n",
    "for i in range(len(df_allagesrace1020['YEAR'])//3):\n",
    "    years.append(2012)\n",
    "    years.append(2016)\n",
    "    years.append(2020)\n",
    "df_allagesrace1020['YEARS']=years\n",
    "df_allagesrace1020=df_allagesrace1020.set_index(['FIPS','YEARS'])\n",
    "df_allagesrace1020=df_allagesrace1020.loc[:,['TOT_POP','NHWA_MALE','NHWA_FEMALE','NHBA_MALE','NHBA_FEMALE',\n",
    "                                             'NHIA_MALE','NHIA_FEMALE','NHAA_MALE','NHAA_FEMALE','NHNA_MALE',\n",
    "                                             'NHNA_FEMALE','NHTOM_MALE','NHTOM_FEMALE','H_MALE','H_FEMALE']]\n",
    "df_race1020=(df_allagesrace1020.T / df_allagesrace1020.TOT_POP).T\n",
    "df_race1020=df_race1020.unstack('YEARS')\n",
    "df_race1020=df_race1020.loc[:,['NHWA_MALE','NHWA_FEMALE','NHBA_MALE','NHBA_FEMALE',\n",
    "                                       'NHIA_MALE','NHIA_FEMALE','NHAA_MALE','NHAA_FEMALE','NHNA_MALE','NHNA_FEMALE',\n",
    "                                       'NHTOM_MALE','NHTOM_FEMALE','H_MALE','H_FEMALE']]\n",
    "#2000-2010\n",
    "df_raceandsex00till10=df_raceandsex00till10.loc[:,['FIPS','SEX','ORIGIN','RACE','POPESTIMATE2000','POPESTIMATE2004','POPESTIMATE2008']]\n",
    "df_raceandsex00till10=df_raceandsex00till10.set_index('FIPS')\n",
    "df_racefractions00till10=pd.DataFrame(columns=['POPESTIMATE2000','POPESTIMATE2004','POPESTIMATE2008'])\n",
    "for i in df_raceandsex00till10.index.unique():\n",
    "    election=['POPESTIMATE2000','POPESTIMATE2004','POPESTIMATE2008']\n",
    "    temp=df_raceandsex00till10.loc[i,election]/df_raceandsex00till10.loc[i,election].iloc[0]\n",
    "    df_racefractions00till10=np.concatenate([df_racefractions00till10,temp])\n",
    "df_racefractions00till10= pd.DataFrame(df_racefractions00till10,index=fipslist,columns=['percentage 2000','percentage 2004','percentage 2008'])   \n",
    "df_racefractions00till10=pd.DataFrame(df_racefractions00till10,index=fipslist,columns=['percentage 2000','percentage 2004','percentage 2008'])\n",
    "df_raceandsex00till10=pd.DataFrame(np.concatenate([df_raceandsex00till10,df_racefractions00till10],axis=1)\n",
    "            ,columns=['SEX','ORIGIN','RACE','POPESTIMATE2000','POPESTIMATE2004','POPESTIMATE2008',\n",
    "                      2000,2004,2008]\n",
    "            )\n",
    "df_raceandsex00till10['FIPS']=fipslist\n",
    "df_raceandsex00till10=df_raceandsex00till10.loc[:,['FIPS','SEX','ORIGIN','RACE',2000,2004,2008]]\n",
    "df_raceandsex00till10=df_raceandsex00till10.set_index(['FIPS','SEX','ORIGIN','RACE'])\n",
    "years=np.repeat([2000,2004,2008],63)\n",
    "\n",
    "df_raceandsex00till10=df_raceandsex00till10.unstack(['SEX','ORIGIN','RACE'])\n",
    "listofused=[]\n",
    "listused2=[]\n",
    "listofused.extend(np.repeat(False,29))\n",
    "listofused.extend(np.repeat(True,7))\n",
    "listofused.extend(np.repeat(False,14))\n",
    "listofused.extend(np.repeat(True,7))\n",
    "listofused.extend(np.repeat(False,6))\n",
    "listused2.extend(listofused)\n",
    "listused2.extend(listofused)\n",
    "listused2.extend(listofused)\n",
    "df_raceandsex00till10=df_raceandsex00till10.loc[:,listused2]\n",
    "df_raceandsex00till10=df_raceandsex00till10.stack(['SEX','ORIGIN','RACE'])\n",
    "\n",
    "df_raceandsex00till10=df_raceandsex00till10.sort_index(level='RACE')\n",
    "df_raceandsex00till10=df_raceandsex00till10.unstack(['SEX','ORIGIN','RACE'])\n",
    "\n",
    "df_raceandsex00till10.columns=[['H_MALE','H_FEMALE','NHWA_MALE','NHWA_FEMALE','NHBA_MALE','NHBA_FEMALE','NHIA_MALE','NHIA_FEMALE',\n",
    "     'NHAA_MALE','NHAA_FEMALE','NHNA_MALE','NHNA_FEMALE','NHTOM_MALE','NHTOM_FEMALE',\n",
    "              'H_MALE','H_FEMALE','NHWA_MALE','NHWA_FEMALE','NHBA_MALE','NHBA_FEMALE','NHIA_MALE','NHIA_FEMALE',\n",
    "     'NHAA_MALE','NHAA_FEMALE','NHNA_MALE','NHNA_FEMALE','NHTOM_MALE','NHTOM_FEMALE',\n",
    "              'H_MALE','H_FEMALE','NHWA_MALE','NHWA_FEMALE','NHBA_MALE','NHBA_FEMALE','NHIA_MALE','NHIA_FEMALE',\n",
    "     'NHAA_MALE','NHAA_FEMALE','NHNA_MALE','NHNA_FEMALE','NHTOM_MALE','NHTOM_FEMALE'],np.repeat([2000,2004,2008],14)]\n",
    "#combine both decades\n",
    "df_race=pd.concat([df_raceandsex00till10,df_race1020],axis=1)\n",
    "df_race.columns.names=['year','race']\n",
    "df_race=df_race.stack('year')\n",
    "df_race=df_race[sorted(df_race.columns)]\n",
    "df_race=df_race.stack('race')\n",
    "df_race=df_race.unstack(['year','race'])\n",
    "\n",
    "\n",
    "total_time_data=pd.concat([total_time_data,df_ages,voterturnout.iloc[:,12:],df_race],axis=1)\n",
    "total_time_data=total_time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed716a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Poverty and median income data are seperated datasets so there the same proces \n",
    "##is repeated 6 times to clean the whole data set\n",
    "\n",
    "#2020\n",
    "df_poverty2019=pd.read_excel('msc_data_raw/median income and poverty/est19all.xls' )\n",
    "df_poverty2019.columns=df_poverty2019.iloc[2]\n",
    "df_poverty2019=df_poverty2019.iloc[3:,:-6]\n",
    "df_poverty2019=df_poverty2019.loc[df_poverty2019['County FIPS Code']!= '000']\n",
    "df_poverty2019['FIPS']=df_poverty2019['State FIPS Code']+df_poverty2019['County FIPS Code']\n",
    "df_poverty2019=df_poverty2019.set_index('FIPS')\n",
    "df_poverty2019=df_poverty2019.loc[:,['Poverty Percent, All Ages','Poverty Percent, Age 0-17','Median Household Income']]\n",
    "\n",
    "#2016\n",
    "df_poverty2016=pd.read_excel('msc_data_raw/median income and poverty/est16all.xls' )\n",
    "df_poverty2016.columns=df_poverty2016.iloc[2]\n",
    "df_poverty2016=df_poverty2016.iloc[3:,:-6]\n",
    "df_poverty2016=df_poverty2016.loc[df_poverty2016['County FIPS Code']!= '000']\n",
    "df_poverty2016['FIPS']=df_poverty2016['State FIPS Code']+df_poverty2016['County FIPS Code']\n",
    "df_poverty2016=df_poverty2016.set_index('FIPS')\n",
    "df_poverty2016=df_poverty2016.loc[:,['Poverty Percent, All Ages','Poverty Percent, Age 0-17','Median Household Income']]\n",
    "\n",
    "#2012\n",
    "df_poverty2012=pd.read_excel('msc_data_raw/median income and poverty/est12all.xls' )\n",
    "df_poverty2012.columns=df_poverty2012.iloc[1]\n",
    "df_poverty2012=df_poverty2012.iloc[2:,:-6]\n",
    "df_poverty2012=df_poverty2012.loc[df_poverty2012['County FIPS Code']!= '000']\n",
    "df_poverty2012['FIPS']=df_poverty2012['State FIPS Code']+df_poverty2012['County FIPS Code']\n",
    "df_poverty2012=df_poverty2012.set_index('FIPS')\n",
    "df_poverty2012=df_poverty2012.loc[:,['Poverty Percent, All Ages','Poverty Percent, Under Age 18','Median Household Income']]\n",
    "\n",
    "#2008\n",
    "df_poverty2008=pd.read_excel('msc_data_raw/median income and poverty/est08all.xls' )\n",
    "df_poverty2008.columns=df_poverty2008.iloc[1]\n",
    "df_poverty2008=df_poverty2008.iloc[2:-3,:-6]\n",
    "fipslist=[]\n",
    "for i in range(len(df_poverty2008)):\n",
    "    if str(df_poverty2008['County FIPS'].iloc[i])=='0':\n",
    "        fipslist.append('000')\n",
    "    elif len(str(df_poverty2008['County FIPS'].iloc[i]))==1:\n",
    "        fipslist.append(df_poverty2008['State FIPS'].iloc[i]+'00' +str(df_poverty2008['County FIPS'].iloc[i]))\n",
    "    elif len(str(df_poverty2008['County FIPS'].iloc[i]))==2:\n",
    "        fipslist.append(df_poverty2008['State FIPS'].iloc[i]+'0' +str(df_poverty2008['County FIPS'].iloc[i]))\n",
    "    elif len(str(df_poverty2008['County FIPS'].iloc[i]))==3:\n",
    "        fipslist.append(df_poverty2008['State FIPS'].iloc[i]+str(df_poverty2008['County FIPS'].iloc[i]))\n",
    "df_poverty2008['FIPS']=fipslist\n",
    "df_poverty2008=df_poverty2008.loc[df_poverty2008['FIPS'] != '000']\n",
    "df_poverty2008=df_poverty2008.set_index('FIPS')\n",
    "df_poverty2008=df_poverty2008.loc[:,['Poverty Percent All Ages','Poverty Percent Under Age 18','Median Household Income']]\n",
    "\n",
    "#2004\n",
    "df_poverty2004=pd.read_excel('msc_data_raw/median income and poverty/est04all.xls' )\n",
    "df_poverty2004.columns=df_poverty2004.iloc[0]\n",
    "df_poverty2004=df_poverty2004.iloc[2:,:-6]\n",
    "fipslistcounty=[]\n",
    "fipslist=[]\n",
    "for i in range(len(df_poverty2004)):\n",
    "    if len(str(df_poverty2004['County FIPS'].iloc[i]))==1:\n",
    "        fipslistcounty.append('00' +str(df_poverty2004['County FIPS'].iloc[i]))\n",
    "    elif len(str(df_poverty2004['County FIPS'].iloc[i]))==2:\n",
    "        fipslistcounty.append('0' +str(df_poverty2004['County FIPS'].iloc[i]))\n",
    "    elif len(str(df_poverty2004['County FIPS'].iloc[i]))==3:\n",
    "        fipslistcounty.append(str(df_poverty2004['County FIPS'].iloc[i]))\n",
    "for i in range(len(df_poverty2004)):\n",
    "    if len(str(df_poverty2004['State FIPS'].iloc[i]))==1:\n",
    "        fipslist.append('0' +str(df_poverty2004['State FIPS'].iloc[i])+fipslistcounty[i])\n",
    "    elif len(str(df_poverty2004['State FIPS'].iloc[i]))==2:\n",
    "        fipslist.append(str(df_poverty2004['State FIPS'].iloc[i])+fipslistcounty[i])\n",
    "df_poverty2004['FIPS']=fipslist\n",
    "df_poverty2004['County_FIPS']=fipslistcounty\n",
    "df_poverty2004=df_poverty2004.loc[df_poverty2004['County_FIPS']!= '000']\n",
    "\n",
    "df_poverty2004=df_poverty2004.set_index('FIPS')\n",
    "df_poverty2004=df_poverty2004.loc[:,['Poverty Percent All Ages','Poverty Percent Under Age 18','Median Household Income']]\n",
    "\n",
    "#2000\n",
    "df_poverty2000=pd.read_excel('msc_data_raw/2000-Census-by-county.xls' ).dropna()\n",
    "df_poverty2000.columns=df_poverty2000.iloc[0]\n",
    "df_childpoverty2000=pd.read_excel('msc_data_raw/childpoverty2000.xlsx' ).dropna()\n",
    "df_medianincome2000=pd.read_excel('msc_data_raw/medianincome2000.xlsx' )\n",
    "df_medianincome2000=df_medianincome2000.iloc[:,0:2].dropna()\n",
    "df_medianincome2000.columns=['FIPS','median income']\n",
    "df_medianincome2000=df_medianincome2000.loc[df_medianincome2000['FIPS'].astype(int)>99]\n",
    "\n",
    "df_medianincome2000=df_medianincome2000.set_index('FIPS')\n",
    "df_poverty2000=df_poverty2000.set_index('State/ County Codes')\n",
    "df_poverty2000=df_poverty2000.iloc[1:,4]\n",
    "df_poverty2000.index.names=['FIPS']\n",
    "df_childpoverty2000=df_childpoverty2000.set_index(df_childpoverty2000.iloc[:,0])\n",
    "df_childpoverty2000=df_childpoverty2000.iloc[:,1]\n",
    "df_medianincome2000\n",
    "\n",
    "df_poverty2000=pd.concat([df_childpoverty2000,df_poverty2000],axis=1)\n",
    "fipslist=[]\n",
    "for i in df_poverty2000.index:\n",
    "    if len(str(i))==4:\n",
    "        fipslist.append('0'+str(i))\n",
    "    else:\n",
    "        fipslist.append(str(i))\n",
    "fipslist            \n",
    "\n",
    "df_poverty2000=df_poverty2000.set_index(pd.Series(fipslist))\n",
    "df_poverty2000=pd.concat([df_poverty2000,df_medianincome2000],axis=1).dropna()\n",
    "df_poverty2000.columns=[[2000,2000,2000],['poverty','youth poverty','median income']]\n",
    "\n",
    "#adding all 6 years together\n",
    "df_poverty=pd.concat([df_poverty2000,df_poverty2004, df_poverty2008,df_poverty2012,df_poverty2016,df_poverty2019],axis=1)\n",
    "df_poverty.columns=[['poverty','youth poverty','median income','poverty','youth poverty','median income',\n",
    "                           'poverty','youth poverty','median income','poverty','youth poverty','median income',\n",
    "                           'poverty','youth poverty','median income','poverty','youth poverty','median income'],\n",
    "                         [2000,2000,2000,2004,2004,2004,2008,2008,2008,2012,2012,2012,2016,2016,2016,2020,2020,2020]]\n",
    "df_poverty=pd.concat([df_poverty['poverty'],df_poverty['youth poverty'],df_poverty['median income']],axis=1)\n",
    "df_poverty.columns=[['poverty','poverty','poverty','poverty','poverty','poverty',\n",
    "                           'youth poverty','youth poverty','youth poverty','youth poverty','youth poverty','youth poverty',\n",
    "                           'median income','median income','median income','median income','median income','median income'],\n",
    "                         [2000,2004,2008,2012,2016,2020,2000,2004,2008,2012,2016,2020,2000,2004,2008,2012,2016,2020]]\n",
    "df_poverty=df_poverty.dropna()\n",
    "df_poverty.loc[:,['poverty','youth poverty']]=df_poverty.loc[:,['poverty','youth poverty']]/100\n",
    "#adding the poverty data to the total data\n",
    "data=data.drop(['poverty','youth poverty','median income'],axis=1)\n",
    "total_time_data=pd.concat([data, df_poverty],axis=1)\n",
    "total_time_data=total_time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The homestates of the presidential candidate and their running mate and incumbancy\n",
    "incumbantdem=[1,0,0,1,1,0]\n",
    "incumbantrep=[0,1,1,0,0,1]\n",
    "homestatedempres=['TN','MA','IL','IL','NY','DE']\n",
    "homestatereppres=['TX','TX','AZ','MA','NY','FL']\n",
    "homestatedemvp=['CT','NC','DE','DE','VA','CA']\n",
    "homestaterepvp=['WY','WY','AK','WI','IN','IN']\n",
    "df_legacydem=pd.DataFrame(list(zip(incumbantdem,homestatedempres,homestatedemvp)),\n",
    "                          index=[2000,2004,2008,2012,2016,2020]\n",
    "                          ,columns=['incumbant', 'homestate of president', 'homestate of vp'])\n",
    "df_legacyrep=pd.DataFrame(list(zip(incumbantrep,homestatereppres,homestaterepvp)),\n",
    "                          index=[2000,2004,2008,2012,2016,2020]\n",
    "                          ,columns=['incumbant', 'homestate of president', 'homestate of vp'])\n",
    "# restructuring this to the general data frame format\n",
    "df_homestatepresdem=pd.DataFrame(index=total_time_data.index)\n",
    "df_homestatevpdem=pd.DataFrame(index=total_time_data.index)\n",
    "\n",
    "for i in df_legacydem.index:\n",
    "    dempres=[]\n",
    "    demvp=[]\n",
    "    presstate=df_legacydem.loc[i,'homestate of president'] \n",
    "    vpstate=df_legacydem.loc[i,'homestate of vp']\n",
    "    presFIPS=Stateinfo.loc[Stateinfo['Code']==presstate]['State FIPS']\n",
    "    vpFIPS=Stateinfo.loc[Stateinfo['Code']==vpstate]['State FIPS']\n",
    "    for j in total_time_data.index:\n",
    "        if str(j)[0:2]==presFIPS.iloc[0]:\n",
    "            dempres.append(1)\n",
    "        else:\n",
    "            dempres.append(0)\n",
    "        if str(j)[0:2]==vpFIPS.iloc[0]:\n",
    "            demvp.append(1)\n",
    "        else:\n",
    "            demvp.append(0)\n",
    "                \n",
    "    df_homestatepresdem[i]=np.array(dempres)\n",
    "    df_homestatevpdem[i]=np.array(demvp)\n",
    "df_homestatepresdem.columns=[['homestate of democratic president','homestate of democratic president','homestate of democratic president',\n",
    "                          'homestate of democratic president','homestate of democratic president','homestate of democratic president',],\n",
    "                          [2000,2004,2008,2012,2016,2020]]\n",
    "df_homestatevpdem.columns=[['homestate of democratic vp','homestate of democratic vp','homestate of democratic vp',\n",
    "                          'homestate of democratic vp','homestate of democratic vp','homestate of democratic vp',],\n",
    "                          [2000,2004,2008,2012,2016,2020]]\n",
    "df_homestatepresrep=pd.DataFrame(index=total_time_data.index)\n",
    "df_homestatevprep=pd.DataFrame(index=total_time_data.index)\n",
    "\n",
    "for i in df_legacydem.index:\n",
    "    reppres=[]\n",
    "    repvp=[]\n",
    "    presstate=df_legacyrep.loc[i,'homestate of president'] \n",
    "    vpstate=df_legacyrep.loc[i,'homestate of vp']\n",
    "    presFIPS=Stateinfo.loc[Stateinfo['Code']==presstate]['State FIPS']\n",
    "    vpFIPS=Stateinfo.loc[Stateinfo['Code']==vpstate]['State FIPS']\n",
    "    for j in total_time_data.index:\n",
    "        if str(j)[0:2]==presFIPS.iloc[0]:\n",
    "            reppres.append(1)\n",
    "        else:\n",
    "            reppres.append(0)\n",
    "        if str(j)[0:2]==vpFIPS.iloc[0]:\n",
    "            repvp.append(1)\n",
    "        else:\n",
    "            repvp.append(0)\n",
    "                \n",
    "    df_homestatepresrep[i]=np.array(reppres)\n",
    "    df_homestatevprep[i]=np.array(repvp)\n",
    "df_homestatepresrep.columns=[['homestate of republican president','homestate of republican president','homestate of republican president',\n",
    "                          'homestate of republican president','homestate of republican president','homestate of republican president',],\n",
    "                          [2000,2004,2008,2012,2016,2020]]\n",
    "df_homestatevprep.columns=[['homestate of republican vp','homestate of republican vp','homestate of republican vp',\n",
    "                          'homestate of republican vp','homestate of republican vp','homestate of republican vp',],\n",
    "                          [2000,2004,2008,2012,2016,2020]]\n",
    "\n",
    "df_incubantdem=pd.DataFrame(index=total_time_data.index)\n",
    "for i in df_legacydem.index:\n",
    "    df_incubantdem[i]=np.repeat(df_legacydem.loc[i,'incumbant'],len(total_time_data.index))\n",
    "df_incubantdem.columns=[['democratic incumbant','democratic incumbant','democratic incumbant',\n",
    "                         'democratic incumbant','democratic incumbant','democratic incumbant'],\n",
    "                        [2000,2004,2008,2012,2016,2020]]\n",
    "#Add to total data\n",
    "total_time_data=pd.concat([total_time_data,df_incubantdem,df_homestatepresdem,df_homestatevpdem,df_homestatepresrep,df_homestatevprep],axis=1)\n",
    "total_time_data=total_time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287410fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Religious data consist out of the census of 2000 and 2010 this data is used to inter and extrapolate\n",
    "#first for 2010\n",
    "fipslist=[]\n",
    "for i in range(len(df_religion10)):\n",
    "    if len(str(df_religion10['FIPS'].iloc[i]))==4:\n",
    "        fipslist.append('0' +str(df_religion10['FIPS'].iloc[i]))\n",
    "    elif len(str(df_religion10['FIPS'].iloc[i]))==5:\n",
    "        fipslist.append(str(df_religion10['FIPS'].iloc[i]))\n",
    "df_religion10['FIPS']=fipslist\n",
    "df_religion10=df_religion10.set_index('FIPS')\n",
    "#religions that where selected \n",
    "religions10=['EVANRATE','CATHRATE','ORTHRATE','AMSHRATE','MSLMRATE','SALVRATE','SBCRATE','UMCRATE']\n",
    "df_religionrate10=pd.DataFrame(index=df_religion10.index)\n",
    "# the following religions consist out of more than one religious sub group\n",
    "df_religionrate10['BAPTRATE']=np.array(df_religion10.loc[:,'ABARATE'])+np.array(df_religion10.loc[:,'ABCRATE'])\n",
    "for i in religions10:\n",
    "    df_religionrate10[i]=np.array(df_religion10.loc[:,i])\n",
    "df_religionrate10['JEWRATE']=np.array(df_religion10.loc[:,'RJUDRATE'])+np.array(df_religion10.loc[:,'OJUDRATE'])+np.array(df_religion10.loc[:,'CJUDRATE'])\n",
    "\n",
    "#for 2000\n",
    "df_religion00=pd.read_csv('msc_data_raw/Religious Congregations and Membership Study, 2000 (Counties File).csv'\n",
    "                          ,sep=';',decimal=',')\n",
    "fipslist=[]\n",
    "for i in range(len(df_religion00)):\n",
    "    if len(str(df_religion00['FIP'].iloc[i]))==4:\n",
    "        fipslist.append('0' +str(df_religion00['FIP'].iloc[i]))\n",
    "    elif len(str(df_religion00['FIP'].iloc[i]))==5:\n",
    "        fipslist.append(str(df_religion00['FIP'].iloc[i]))\n",
    "df_religion00['FIPS']=fipslist\n",
    "df_religion00=df_religion00.set_index('FIPS')\n",
    "religions00=['EVANRT','CATHRT','ORTHRT','AMOTHRT','ISLAMRT','SALARRT','SBCRT','UMETHRT','JEWRT']\n",
    "df_religionrate00=pd.DataFrame(index=df_religion00.index)\n",
    "df_religionrate00['BAPTRT']=np.array(df_religion00.loc[:,'AMBAPRT'])+np.array(df_religion00.loc[:,'ABAPRT'])\n",
    "for i in religions00:\n",
    "    df_religionrate00[i]=np.array(df_religion00.loc[:,i])\n",
    "    \n",
    "#combine both years in one dataframe\n",
    "df_religion=pd.concat([df_religionrate00,df_religionrate10],axis=1).dropna()\n",
    "\n",
    "#using the inter and extrapolation to estimate the religions for the election years\n",
    "df_religionrate=pd.DataFrame(index=df_religion00.index)\n",
    "years=[]\n",
    "for i in range(len(df_religionrate00.columns)):\n",
    "    year00=np.array(df_religion.loc[:,df_religionrate00.columns[i]])\n",
    "    year10=np.array(df_religion.loc[:,df_religionrate10.columns[i]])\n",
    "    diff=year10-year00\n",
    "    df_religionrate[df_religionrate10.columns[i]+'2000'] = year00\n",
    "    df_religionrate[df_religionrate10.columns[i]+'2004'] = year00*6/10+year10*4/10\n",
    "    df_religionrate[df_religionrate10.columns[i]+'2008'] = year00*2/10+year10*8/10\n",
    "    temp=year10 +diff*2/10\n",
    "    df_religionrate[df_religionrate10.columns[i]+'2012'] =  np.where(temp <0, 0, temp)\n",
    "    temp=year10 +diff*6/10\n",
    "    df_religionrate[df_religionrate10.columns[i]+'2016'] = np.where(temp <0, 0, temp)\n",
    "    temp=year10 +diff\n",
    "    df_religionrate[df_religionrate10.columns[i]+'2020'] = np.where(temp <0, 0, temp)\n",
    "    years.append(2000)\n",
    "    years.append(2004)\n",
    "    years.append(2008)\n",
    "    years.append(2012)\n",
    "    years.append(2016)\n",
    "    years.append(2020)\n",
    "df_religionrate.columns=[np.repeat(df_religionrate10.columns,6),years]\n",
    "\n",
    "#add to total data\n",
    "total_time_data=pd.concat([total_time_data,df_religionrate],axis=1)\n",
    "total_time_data=total_time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# education here the data that is availible is for 2000 and 2015-2019 so again inter and extrapolation is needed\n",
    "df_education=pd.read_excel('msc_data_raw/Education.xls')\n",
    "df_education.columns=df_education.iloc[3]\n",
    "df_education=df_education.iloc[6:].dropna()\n",
    "\n",
    "lesshighschool2015=np.array(df_education['Percent of adults with less than a high school diploma, 2015-19'])\n",
    "highschool2015=np.array(df_education['Percent of adults with a high school diploma only, 2015-19'])\n",
    "bsc2015=np.array(df_education[\"Percent of adults with a bachelor's degree or higher, 2015-19\"])\n",
    "lesshighschool2000=np.array(df_education['Percent of adults with less than a high school diploma, 2000'])\n",
    "highschool2000=np.array(df_education['Percent of adults with a high school diploma only, 2000'])\n",
    "bsc2000=np.array(df_education[\"Percent of adults with a bachelor's degree or higher, 2000\"])\n",
    "df_lesshighschool=pd.DataFrame(index=df_education['FIPS Code'])\n",
    "df_lesshighschool[2000]=lesshighschool2000\n",
    "df_lesshighschool[2004]=lesshighschool2000*11/15+lesshighschool2015*4/15\n",
    "df_lesshighschool[2008]=lesshighschool2000*7/15+lesshighschool2015*8/15\n",
    "df_lesshighschool[2012]=lesshighschool2000*3/15+lesshighschool2015*12/15\n",
    "df_lesshighschool[2016]=lesshighschool2000*1/15+lesshighschool2015*14/15\n",
    "df_lesshighschool[2020]=lesshighschool2015\n",
    "df_lesshighschool.columns=[np.repeat('Less than highschool',6),df_lesshighschool.columns]\n",
    "df_highschool=pd.DataFrame(index=df_education['FIPS Code'])\n",
    "df_highschool[2000]=highschool2000\n",
    "df_highschool[2004]=highschool2000*11/15+highschool2015*4/15\n",
    "df_highschool[2008]=highschool2000*7/15+highschool2015*8/15\n",
    "df_highschool[2012]=highschool2000*3/15+highschool2015*12/15\n",
    "df_highschool[2016]=highschool2000*1/15+highschool2015*14/15\n",
    "df_highschool[2020]=highschool2015\n",
    "df_highschool.columns=[np.repeat('Highschool',6),df_highschool.columns]\n",
    "df_bsc=pd.DataFrame(index=df_education['FIPS Code'])\n",
    "df_bsc[2000]=bsc2000\n",
    "df_bsc[2004]=bsc2000*11/15+bsc2015*4/15\n",
    "df_bsc[2008]=bsc2000*7/15+bsc2015*8/15\n",
    "df_bsc[2012]=bsc2000*3/15+bsc2015*12/15\n",
    "df_bsc[2016]=bsc2000*1/15+bsc2015*14/15\n",
    "df_bsc[2020]=bsc2015\n",
    "df_bsc.columns=[np.repeat('Bachelor',6),df_bsc.columns]\n",
    "\n",
    "#add to total data\n",
    "total_time_data=pd.concat([total_time_data,df_lesshighschool,df_highschool,df_bsc],axis=1)\n",
    "total_time_data=total_time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3895338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the rural-urban continuum code the sort counties in rural, metro and metro adjacent\n",
    "\n",
    "df_rural13=pd.read_excel('msc_data_raw/ruralurbancodes2013.xls')\n",
    "fipslist=[]\n",
    "for i in range(len(df_rural13)):\n",
    "    if len(str(df_rural13['FIPS'].iloc[i]))==4:\n",
    "        fipslist.append('0' +str(df_rural13['FIPS'].iloc[i]))\n",
    "    elif len(str(df_rural13['FIPS'].iloc[i]))==5:\n",
    "        fipslist.append(str(df_rural13['FIPS'].iloc[i]))\n",
    "df_rural13['FIPS']=fipslist\n",
    "df_rural13=df_rural13.set_index('FIPS')\n",
    "df_rural1020=pd.DataFrame(index=df_rural.index)\n",
    "df_rural03=pd.read_excel('msc_data_raw/ruralurbancodes2003.xls')\n",
    "fipslist=[]\n",
    "for i in range(len(df_rural03)):\n",
    "    if len(str(df_rural03['FIPS Code'].iloc[i]))==4:\n",
    "        fipslist.append('0' +str(df_rural03['FIPS Code'].iloc[i]))\n",
    "    elif len(str(df_rural03['FIPS Code'].iloc[i]))==5:\n",
    "        fipslist.append(str(df_rural03['FIPS Code'].iloc[i]))\n",
    "df_rural03['FIPS']=fipslist\n",
    "df_rural03=df_rural03.set_index('FIPS')\n",
    "\n",
    "df_rural0010=pd.DataFrame(index=df_rural.index)\n",
    "df_rural0010[2000]=np.array(df_rural['2003 Rural-urban Continuum Code'])*1.3-np.array(df_rural['RUCC_2013'])*0.3<=3\n",
    "df_rural0010[2004]=np.array(df_rural['2003 Rural-urban Continuum Code'])*0.9+np.array(df_rural['RUCC_2013'])*0.1<=3\n",
    "df_rural0010[2008]=np.array(df_rural['2003 Rural-urban Continuum Code'])*0.5+np.array(df_rural['RUCC_2013'])*0.5<=3\n",
    "df_rural1020[2012]=np.array(df_rural['2003 Rural-urban Continuum Code'])*0.1+np.array(df_rural['RUCC_2013'])*0.9<=3\n",
    "df_rural1020[2016]=np.array(-df_rural['2003 Rural-urban Continuum Code'])*0.3+np.array(df_rural['RUCC_2013'])*1.3<=3\n",
    "df_rural1020[2020]=np.array(-df_rural['2003 Rural-urban Continuum Code'])*0.7+np.array(df_rural['RUCC_2013'])*1.7<=3\n",
    "\n",
    "\n",
    "\n",
    "df_rural0010[20002]=np.array(df_rural['2003 Rural-urban Continuum Code'])*1.3-np.array(df_rural['RUCC_2013'])*0.3<=6  -np.array(df_rural0010[2000])\n",
    "df_rural0010[20042]=np.array(df_rural['2003 Rural-urban Continuum Code'])*0.9+np.array(df_rural['RUCC_2013'])*0.1<=6 -np.array(df_rural0010[2004])\n",
    "df_rural0010[20082]=np.array(df_rural['2003 Rural-urban Continuum Code'])*0.5+np.array(df_rural['RUCC_2013'])*0.5<=6 -np.array(df_rural0010[2008])\n",
    "df_rural1020[20122]=np.array(df_rural['2003 Rural-urban Continuum Code'])*0.1+np.array(df_rural['RUCC_2013'])*0.9<=6 -np.array(df_rural1020[2012])\n",
    "df_rural1020[20162]=np.array(-df_rural['2003 Rural-urban Continuum Code'])*0.3+np.array(df_rural['RUCC_2013'])*1.3<=6-np.array(df_rural1020[2016])\n",
    "df_rural1020[20202]=np.array(-df_rural['2003 Rural-urban Continuum Code'])*0.7+np.array(df_rural['RUCC_2013'])*1.7<=6-np.array(df_rural1020[2020])\n",
    "\n",
    "df_rural1020.columns=[['metro','metro','metro','metro adjacent','metro adjacent','metro adjacent'],[2012,2016,2020,2012,2016,2020]]\n",
    "df_rural0010.columns=[['metro','metro','metro','metro adjacent','metro adjacent','metro adjacent'],[2000,2004,2008,2000,2004,2008]]\n",
    "\n",
    "df_rural = pd.concat([df_rural0010,df_rural1020],axis=1).dropna()\n",
    "df_rural=df_rural.sort_index(axis=1)\n",
    "df_rural.index=df_rural.index.map(int)\n",
    "\n",
    "#add to total data\n",
    "total_time_data=pd.concat([total_time_data,df_rural],axis=1)\n",
    "total_time_data=total_time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cae38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values of S&P, Nasdaq and the inflation rate\n",
    "df_SP500=pd.DataFrame(index=total_time_data.index)\n",
    "electionyears=[2000,2004,2008,2012,2016,2020]\n",
    "SPvalues=[1421.22,1130.54,971.31,1417.26,2129.92,3336.25]\n",
    "for i in range(6):\n",
    "    df_SP500[electionyears[i]]=np.repeat(SPvalues[i],total_time_data.shape[0])\n",
    "df_SP500.columns=[np.repeat('SP500',6),electionyears]\n",
    "\n",
    "df_nasdaq=pd.DataFrame(index=total_time_data.index)\n",
    "nasdaq=[3399.28,1981.47,1761.09,3003.71,5154.99,11038.66]\n",
    "for i in range(6):\n",
    "    df_nasdaq[electionyears[i]]=np.repeat(nasdaq[i],total_time_data.shape[0])\n",
    "df_nasdaq.columns=[np.repeat('nasdaq',6),electionyears]\n",
    "\n",
    "df_inflation=pd.DataFrame(index=total_time_data.index)\n",
    "inflation=[3.4,2.7,3.8,2.1,1.3,1.2]\n",
    "for i in range(6):\n",
    "    df_inflation[electionyears[i]]=np.repeat(inflation[i],total_time_data.shape[0])\n",
    "df_inflation.columns=[np.repeat('inflation',6),electionyears]\n",
    "\n",
    "total_time_data=pd.concat([total_time_data,df_inflation,df_SP500,df_nasdaq],axis=1)\n",
    "total_time_data=total_time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the presidential events a function is written to webscrape\n",
    "def url_get_contents(url):\n",
    " \n",
    "    # Opens a website and read its\n",
    "    # binary contents (HTTP Response Body)\n",
    " \n",
    "    #making request to the website\n",
    "    req = urllib.request.Request(url=url)\n",
    "    f = urllib.request.urlopen(req)\n",
    "    #f=open(req, 'r', encoding = get_encoding_type, errors='ignore')\n",
    "    #reading contents of the website\n",
    "    return f.read()\n",
    "# funcrtion to count number of visits\n",
    "def retrieve_visits(month,year,person,camp):\n",
    "    if year==2020:\n",
    "        url='https://www.democracyinaction.us/'+str(year)+'/' +camp+'/'+str(person)+'cal'+str(month)+str(year)[-2:]+'.html'\n",
    "    else:\n",
    "        url='http://p'+str(year)+'.org/'+str(camp)+'/'+str(person)+'cal'+str(month)+str(year)[-2:]+'a.html'\n",
    "    if month=='08':\n",
    "        try:\n",
    "            xhtml = url_get_contents(url).decode('cp1252')\n",
    "        except Exception:\n",
    "            return []\n",
    "    else:\n",
    "        try:\n",
    "            xhtml = url_get_contents(url).decode('utf-8')\n",
    "        except Exception:\n",
    "            return []\n",
    "    p = HTMLTableParser()\n",
    "    p.feed(xhtml)\n",
    "    temp1=[]\n",
    "    for i in p.tables:\n",
    "        for j in i:\n",
    "            for k in j:\n",
    "                if len(k)>5:\n",
    "                    temp1.append(k)\n",
    "    temp2=[]\n",
    "    for i in temp1:\n",
    "        temp2.append(re.split('\\s\\s', i))\n",
    "       \n",
    "    temp3=[]\n",
    "    for i in temp2:\n",
    "        for j in i:\n",
    "            if len(j)>5 and len(j)<50:\n",
    "                temp3.append(j)\n",
    "    \n",
    "    temp4=[]\n",
    "    for i in temp3:\n",
    "        temp4.append(re.split('[()]', i))\n",
    "    \n",
    "    visits=[]\n",
    "    \n",
    "    for i in temp4:\n",
    "        #print(i)\n",
    "        for j in i:\n",
    "            if len(j)>5 and len(j)<50:\n",
    "                visits.append(j)\n",
    "    return visits\n",
    "\n",
    "#now the function above will be used to loop over all elections and candidates\n",
    "city=pd.read_csv('msc_data_raw/zip_code_database.csv')\n",
    "df_visits=pd.DataFrame(index=df_education['FIPS Code'],columns=['county','State'])\n",
    "df_visits['county']=df_education.set_index('FIPS Code')['Area name']\n",
    "df_visits['State']=df_education.set_index('FIPS Code')['State']\n",
    "allcandidates=[]\n",
    "for j in [2000,2004,2008,2012,2016,2020]:\n",
    "    n=-1\n",
    "    if j==2000:\n",
    "        candidates=['bush','cheney','lbush','gore','lieberman','tipper']\n",
    "    elif j==2004:   \n",
    "        candidates=['bush','cheney','lbush','kerry','edwards','thk']\n",
    "    elif j==2008:\n",
    "        candidates=['mccain','palin','cindy','obama','biden','michelle']\n",
    "    elif j==2012:\n",
    "        candidates=['romney','ryan','ann','obama','biden','michelle']\n",
    "    elif j==2016:\n",
    "        candidates=['trump','pence','ivana','clinton','kaine','billclinton']\n",
    "    elif j==2020:\n",
    "        candidates=['trump','pence','ivana','biden','harris','jillbiden']\n",
    "    allcandidates.extend(candidates)\n",
    "    for k in candidates:\n",
    "        df_visits[k+str(j)]=np.repeat(0,len(df_visits))\n",
    "        n+=1\n",
    "        visits=[]\n",
    "        for i in ['03','04','05','06','07','08','09','10']:\n",
    "            if n>=3:\n",
    "                l=candidates[3]\n",
    "            else:\n",
    "                l=candidates[0]\n",
    "            temp=retrieve_visits(i,j,k,l)\n",
    "            visits.extend(temp)\n",
    "            \n",
    "            \n",
    "            df_visitstemp=pd.DataFrame(index=range(len(visits)),columns=['county','state'])\n",
    "            for i in range(len(visits)):\n",
    "                try:\n",
    "                    df_visitstemp.iloc[i]=re.split(',', visits[i])\n",
    "                except Exception:\n",
    "                    df_visitstemp.loc[i]=np.nan\n",
    "                if df_visitstemp.loc[i,'county']==df_visitstemp.loc[i,'state']:\n",
    "                    df_visitstemp.loc[i]=np.nan\n",
    "            df_visitstemp=df_visitstemp.dropna()\n",
    "            for i in df_visitstemp.index:\n",
    "                df_visitstemp.loc[i,'state']=df_visitstemp.loc[i,'state'][-2:]\n",
    "                \n",
    "                \n",
    "            for i in range(len(df_visitstemp)):\n",
    "                county=df_visitstemp.iloc[i,0]\n",
    "                state=df_visitstemp.iloc[i,1]\n",
    "                istar=county+' County' \n",
    "                if np.sum(np.array(df_visits['county']==county)*np.array(df_visits['State']==state))!=0 or np.sum(np.array(df_visits['county']==istar)*np.array(df_visits['State']==state))!=0:\n",
    "                    df_visits[k+str(j)]=np.array(df_visits['county']==county)*np.array(df_visits['State']==state)+np.array(df_visits[k+str(j)])\n",
    "                    df_visits[k+str(j)]=np.array(df_visits['county']==istar)*np.array(df_visits['State']==state)+np.array(df_visits[k+str(j)])\n",
    "                elif state in set(city.loc[city.loc[:,'primary_city']==county]['state']):\n",
    "                    real_county=city.loc[city.loc[:,'primary_city']==county][np.array(city.loc[city.loc[:,'primary_city']==county]['state']==state)]['county'].iloc[0]\n",
    "                    df_visits[k+str(j)]=np.array(df_visits['county']==real_county)*np.array(df_visits['State']==state)+np.array(df_visits[k+str(j)])\n",
    "            \n",
    "#putting it in one dataframe\n",
    "df_visits=df_visits.drop(['county','State'],axis=1)\n",
    "df_visits.columns=[np.repeat([2000,2004,2008,2012,2016,2020],6),['visits_rep_pres','visits_rep_vp','visits_rep_FL','visits_dem_pres','visits_dem_vp','visits_dem_FL',\n",
    "                                                                'visits_rep_pres','visits_rep_vp','visits_rep_FL','visits_dem_pres','visits_dem_vp','visits_dem_FL',\n",
    "                                                                'visits_rep_pres','visits_rep_vp','visits_rep_FL','visits_dem_pres','visits_dem_vp','visits_dem_FL',\n",
    "                                                                'visits_rep_pres','visits_rep_vp','visits_rep_FL','visits_dem_pres','visits_dem_vp','visits_dem_FL',\n",
    "                                                                'visits_rep_pres','visits_rep_vp','visits_rep_FL','visits_dem_pres','visits_dem_vp','visits_dem_FL',\n",
    "                                                                'visits_rep_pres','visits_rep_vp','visits_rep_FL','visits_dem_pres','visits_dem_vp','visits_dem_FL']]\n",
    "\n",
    "df_total_visits=pd.DataFrame(index=df_visits.index, columns=[np.repeat([2000,2004,2008,2012,2016,2020],2),\n",
    "                                                            ['visits_dem','visits_rep','visits_dem','visits_rep','visits_dem','visits_rep',\n",
    "                                                            'visits_dem','visits_rep','visits_dem','visits_rep','visits_dem','visits_rep']])\n",
    "for i in [2000,2004,2008,2012,2016,2020]:\n",
    "    df_total_visits.loc[:,(i,'visits_rep')]=np.sum(df_visits[i].iloc[:,:3],axis=1)\n",
    "    df_total_visits.loc[:,(i,'visits_dem')]=np.sum(df_visits[i].iloc[:,3:],axis=1)\n",
    "df_total_visits=df_total_visits.swaplevel(axis=1).sort_index(axis=1)\n",
    "df_visits=df_visits.swaplevel(axis=1).sort_index(axis=1)\n",
    "# the corrected visits is the visits divided by eligible voters\n",
    "df_corrected_visits_dem=pd.DataFrame(index=df_total_visits.index,columns=[np.repeat('corrected total dem visits',6),\n",
    "                                                                         [2000,2004,2008,2012,2016,2020]])\n",
    "temp = pd.concat([df_total_visits.iloc[:,:6],df_eligibevoters],axis=1).dropna()\n",
    "temp\n",
    "df_corrected_visits_dem=temp['visits_dem']/temp['eligible voters']*50000\n",
    "df_corrected_visits_dem.columns=[np.repeat('corrected total dem visits',6),\n",
    "                                [2000,2004,2008,2012,2016,2020]]\n",
    "df_corrected_visits_rep=pd.DataFrame(index=df_total_visits.index,columns=[np.repeat('corrected total rep visits',6),\n",
    "                                                                         [2000,2004,2008,2012,2016,2020]])\n",
    "temp = pd.concat([df_total_visits.iloc[:,6:],df_eligibevoters],axis=1).dropna()\n",
    "temp\n",
    "df_corrected_visits_rep=temp['visits_rep']/temp['eligible voters']*5000\n",
    "df_corrected_visits_rep.columns=[np.repeat('corrected total rep visits',6),\n",
    "                                [2000,2004,2008,2012,2016,2020]]\n",
    "\n",
    "total_time_data=pd.concat([total_time_data,df_total_visits,df_visits,df_corrected_visits_rep,df_corrected_visits_dem],axis=1)\n",
    "total_time_data=total_time_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the cleaned data\n",
    "#total_time_data.to_csv('msc_thesis/data/totaldata')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
